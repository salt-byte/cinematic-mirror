/**
 * Gemini Live API æœåŠ¡
 * å‚è€ƒå·¥ä½œä»£ç é‡å†™ï¼Œå®ç°å®æ—¶éŸ³è§†é¢‘å¯¹è¯
 */

import { GoogleGenAI, Modality } from '@google/genai';

const LIVE_MODEL = 'gemini-2.5-flash-native-audio-preview-12-2025';

const getApiKey = (): string => {
    // @ts-ignore
    return import.meta.env?.VITE_GEMINI_API_KEY || '';
};

export interface LiveSessionConfig {
    systemInstruction?: string;
    voiceName?: string;
    onAudioData?: (audioData: ArrayBuffer) => void;
    onTextResponse?: (text: string) => void;
    onError?: (error: Error) => void;
    onConnected?: () => void;
    onDisconnected?: () => void;
    onInterrupted?: () => void;
}

class GeminiLiveService {
    private session: any = null;
    private config: LiveSessionConfig = {};
    private audioContext: AudioContext | null = null;
    private isConnected = false;
    private nextStartTime = 0;
    private activeSources: Set<AudioBufferSourceNode> = new Set();

    initAudioContext(): void {
        if (!this.audioContext) {
            this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 24000 });
            console.log('ğŸ”Š AudioContext initialized (24000Hz)');
        }
        if (this.audioContext.state === 'suspended') {
            this.audioContext.resume();
            console.log('ğŸ”Š AudioContext resumed');
        }
    }

    async connect(config: LiveSessionConfig): Promise<void> {
        this.config = config;

        const apiKey = getApiKey();
        if (!apiKey) {
            throw new Error('Missing Gemini API Key');
        }

        try {
            const ai = new GoogleGenAI({ apiKey });

            this.session = await ai.live.connect({
                model: LIVE_MODEL,
                callbacks: {
                    onopen: () => {
                        console.log('âœ… Live API connected');
                        this.isConnected = true;
                        this.nextStartTime = 0;
                        this.config.onConnected?.();
                    },
                    onmessage: (message: any) => {
                        this.handleMessage(message);
                    },
                    onerror: (error: any) => {
                        console.error('âŒ Live API error:', error);
                        this.config.onError?.(error instanceof Error ? error : new Error(String(error)));
                    },
                    onclose: () => {
                        console.log('ğŸ“´ Live API disconnected');
                        this.isConnected = false;
                        this.config.onDisconnected?.();
                    }
                },
                config: {
                    responseModalities: [Modality.AUDIO],
                    systemInstruction: config.systemInstruction || 'ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æœè£…é€ å‹é¡¾é—®ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œè¯­æ°”æ¸©æš–ä¸“ä¸šã€‚',
                    speechConfig: {
                        voiceConfig: {
                            prebuiltVoiceConfig: {
                                voiceName: config.voiceName || 'Zephyr'
                            }
                        }
                    },
                    // å…³é”®ï¼šå¯ç”¨è½¬å½•
                    outputAudioTranscription: {},
                    inputAudioTranscription: {},
                }
            });

        } catch (error: any) {
            console.error('Failed to connect:', error);
            throw error;
        }
    }

    private handleMessage(message: any): void {
        try {
            // å¤„ç†ä¸­æ–­
            if (message.serverContent?.interrupted) {
                console.log('âš¡ Interrupted');
                this.stopAllAudio();
                this.config.onInterrupted?.();
                return;
            }

            // å¤„ç†éŸ³é¢‘æ•°æ® - å…³é”®è·¯å¾„
            const audioPart = message.serverContent?.modelTurn?.parts?.[0];
            if (audioPart?.inlineData?.data) {
                const base64Audio = audioPart.inlineData.data;
                console.log('ğŸ”Š Got audio data, length:', base64Audio.length);
                this.playBase64Audio(base64Audio);
            }

            // å¤„ç†è¾“å‡ºè½¬å½•ï¼ˆAIè¯´çš„è¯ï¼‰
            if (message.serverContent?.outputTranscription?.text) {
                const text = message.serverContent.outputTranscription.text;
                console.log('ğŸ“ AI transcript:', text);
                this.config.onTextResponse?.(text);
            }

            // å¤„ç†è¾“å…¥è½¬å½•ï¼ˆç”¨æˆ·è¯´çš„è¯ï¼‰
            if (message.serverContent?.inputTranscription?.text) {
                console.log('ğŸ¤ User transcript:', message.serverContent.inputTranscription.text);
            }

            // å¤„ç†å›åˆå®Œæˆ
            if (message.serverContent?.turnComplete) {
                console.log('âœ”ï¸ Turn complete');
            }

        } catch (error) {
            console.error('Error handling message:', error);
        }
    }

    private async playBase64Audio(base64: string): Promise<void> {
        if (!this.audioContext) {
            this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 24000 });
        }

        if (this.audioContext.state === 'suspended') {
            await this.audioContext.resume();
        }

        try {
            // è§£ç  base64
            const binaryString = atob(base64);
            const bytes = new Uint8Array(binaryString.length);
            for (let i = 0; i < binaryString.length; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }

            // PCM 16-bit è½¬ AudioBuffer
            const dataInt16 = new Int16Array(bytes.buffer);
            const sampleRate = 24000;
            const channels = 1;
            const frameCount = dataInt16.length / channels;

            const audioBuffer = this.audioContext.createBuffer(channels, frameCount, sampleRate);
            const channelData = audioBuffer.getChannelData(0);

            for (let i = 0; i < frameCount; i++) {
                channelData[i] = dataInt16[i] / 32768.0;
            }

            // ä½¿ç”¨é˜Ÿåˆ—æ’­æ”¾ï¼Œé¿å…éŸ³é¢‘é‡å 
            this.nextStartTime = Math.max(this.nextStartTime, this.audioContext.currentTime);

            const source = this.audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(this.audioContext.destination);
            source.start(this.nextStartTime);

            this.nextStartTime += audioBuffer.duration;
            this.activeSources.add(source);

            this.config.onAudioData?.(bytes.buffer);

            source.onended = () => {
                this.activeSources.delete(source);
            };

            console.log('ğŸ”Š Playing audio, duration:', audioBuffer.duration.toFixed(2), 's');

        } catch (error) {
            console.error('Error playing audio:', error);
        }
    }

    private stopAllAudio(): void {
        this.activeSources.forEach(source => {
            try { source.stop(); } catch (e) {}
        });
        this.activeSources.clear();
        this.nextStartTime = 0;
    }

    sendAudio(audioData: ArrayBuffer): void {
        if (!this.isConnected || !this.session) return;

        try {
            // è½¬æ¢ä¸º base64
            const bytes = new Uint8Array(audioData);
            let binary = '';
            for (let i = 0; i < bytes.byteLength; i++) {
                binary += String.fromCharCode(bytes[i]);
            }
            const base64 = btoa(binary);

            this.session.sendRealtimeInput({
                media: {
                    data: base64,
                    mimeType: 'audio/pcm;rate=16000'
                }
            });
        } catch (error) {
            console.error('Error sending audio:', error);
        }
    }

    sendVideoFrame(imageData: string): void {
        if (!this.isConnected || !this.session) return;

        try {
            const base64Image = imageData.replace(/^data:image\/\w+;base64,/, '');
            this.session.sendRealtimeInput({
                media: {
                    data: base64Image,
                    mimeType: 'image/jpeg'
                }
            });
        } catch (error) {
            console.error('Error sending video frame:', error);
        }
    }

    sendText(text: string): void {
        if (!this.isConnected || !this.session) return;

        try {
            this.session.sendRealtimeInput({ text });
        } catch (error) {
            console.error('Error sending text:', error);
        }
    }

    disconnect(): void {
        this.stopAllAudio();

        if (this.session) {
            try { this.session.close(); } catch (e) {}
            this.session = null;
        }
        this.isConnected = false;

        if (this.audioContext) {
            this.audioContext.close();
            this.audioContext = null;
        }
    }

    isSessionActive(): boolean {
        return this.isConnected;
    }
}

export const geminiLive = new GeminiLiveService();
export default geminiLive;
